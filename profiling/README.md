Here we include results of profiling the error models from the `tab_err` library.

We used a python memory profiler accessible (here)[https://pypi.org/project/memory-profiler/] and used wall clock timing before and after the call in the code used to profile runtime.

The profiling plots used in the paper are available in the `plots` directory. They are generated by the `profile_paper_plots.ipynb` file.

The memory and runtime profiling results can be obtained (while in the `profiling` directory) with commands such as `poetry run -- python3 src/profile_numeric.py` and `poetry run -- python3 src/profile_string.py`. The runtime will be immediately available as `results/numeric_times.csv` and `results/string_times.csv`. The memory results need an extra step to process due to the lack of a python API for results aggregation in the memray library. That is, one must run `poetry run -- python3 src/numeric_memray_results_allocation.py` and `poetry run -- python3 src/string_memray_results_allocation.py` to obtain the results for numeric and string in the JSON files `results/numeric_mem_result.json` and `results/string_mem_results.json` for the string and numeric data types respectively. After this is complete plotting may be done in the aforementioned `.ipynb` file.

Our results were obtained from the BHT Berlin compute cluster with 32000m CPU and 16Gb RAM used for each data type though only one core was used per instance of runtime and memory profile. The system specifications are in the paper.

## Quickstart Guide:

In the `profiling` directory do the following:

1. Generate profiling results: `poetry run -- python3 src/profile_numeric.py` and `poetry run -- python3 src/profile_string.py`

2. Aggregate memory results: `poetry run -- python3 src/numeric_memray_results_allocation.py` and `poetry run -- python3 src/string_memray_results_allocation.py`

3. Plot with by running the notebook: `profile_paper_plots.ipynb`
